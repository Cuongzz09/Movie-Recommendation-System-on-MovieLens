{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Datasets Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies dataset shape: (3883, 5)\n",
      "   movieId                        title                        genres  year  \\\n",
      "0        1                    Toy Story   Animation|Children's|Comedy  1995   \n",
      "1        2                      Jumanji  Adventure|Children's|Fantasy  1995   \n",
      "2        3             Grumpier Old Men                Comedy|Romance  1995   \n",
      "3        4            Waiting to Exhale                  Comedy|Drama  1995   \n",
      "4        5  Father of the Bride Part II                        Comedy  1995   \n",
      "\n",
      "                                         description  \n",
      "0  Led by Woody, Andy's toys live happily in his ...  \n",
      "1  When siblings Judy and Peter discover an encha...  \n",
      "2  A family wedding reignites the ancient feud be...  \n",
      "3  Cheated on, mistreated and stepped on, the wom...  \n",
      "4  Just when George Banks has recovered from his ...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Load movie metadata with descriptions.\n",
    "# This file must include columns: movieId, title, genres, year, description.\n",
    "if os.path.exists(\"movielens_movies_with_descriptions.csv\"):\n",
    "    movies_with_des_dir = \"movielens_movies_with_descriptions.csv\"\n",
    "else:\n",
    "    movies_with_des_dir = \"../movielens_movies_with_descriptions.csv\"\n",
    "movies_df = pd.read_csv(movies_with_des_dir)\n",
    "print(\"Movies dataset shape:\", movies_df.shape)\n",
    "print(movies_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings dataset shape: (1000209, 4)\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Load ratings data.\n",
    "# The ratings file is delimited by \"::\". Adjust file path as needed.\n",
    "if os.path.exists('movielens-1m/ratings.dat'):\n",
    "    ratings_dir = 'movielens-1m/ratings.dat'\n",
    "else:\n",
    "    ratings_dir = '../movielens-1m/ratings.dat'\n",
    "ratings_df = pd.read_csv(ratings_dir, sep='::', engine='python',\n",
    "                         header=None, names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "print(\"Ratings dataset shape:\", ratings_df.shape)\n",
    "print(ratings_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users dataset shape: (6040, 5)\n",
      "   userId Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Load user demographics for further analysis.\n",
    "if os.path.exists('movielens-1m/users.dat'):\n",
    "    users_dir = 'movielens-1m/users.dat'\n",
    "else:\n",
    "    users_dir = '../movielens-1m/users.dat'\n",
    "users_df = pd.read_csv(users_dir, sep='::', engine='python',\n",
    "                       header=None, names=['userId', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
    "print(\"Users dataset shape:\", users_df.shape)\n",
    "print(users_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create the User-Item Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item matrix shape (R_df): (6040, 3706)\n"
     ]
    }
   ],
   "source": [
    "# Pivot the ratings data so that rows represent users and columns represent movies.\n",
    "# Missing ratings are filled with zeros.\n",
    "R_df = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "print(\"User-Item matrix shape (R_df):\", R_df.shape)\n",
    "# print(R_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Prepare Training Data and Apply SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (800167, 4)\n",
      "Test set size: (200042, 4)\n"
     ]
    }
   ],
   "source": [
    "# To follow the SVD formula from the PDF:\n",
    "#   1. Center the data: R_adj = R - mean(R) per user.\n",
    "#   2. Decompose the centered matrix: R_adj = U Σ Vᵀ.\n",
    "#   3. Reconstruct the prediction: R_predicted = U Σ Vᵀ + mean(R).\n",
    "\n",
    "# Split the ratings into training and test sets (80% train, 20% test).\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "print(\"Train set size:\", train_data.shape)\n",
    "print(\"Test set size:\", test_data.shape)\n",
    "\n",
    "# Build the training matrix from R_df and then mask the test ratings.\n",
    "R_train_df = R_df.copy()\n",
    "# For simplicity, here we assume R_df is built from all ratings and then we mask test entries.\n",
    "for idx, row in test_data.iterrows():\n",
    "    # Set the entry corresponding to each test rating to 0 (masking)\n",
    "    R_train_df.at[row['userId'], row['movieId']] = 0\n",
    "\n",
    "# Convert the training DataFrame to a NumPy array.\n",
    "R_train = R_train_df.values\n",
    "\n",
    "# Apply SVD Using the Formulas (Centering, Decomposition, Reconstruction)\n",
    "# Compute each user's mean rating from the training data.\n",
    "user_ratings_mean = np.mean(R_train, axis=1)\n",
    "# Center the training matrix (this is X_adj in the formulas).\n",
    "R_train_demeaned = R_train - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# Perform SVD on the demeaned training matrix.\n",
    "# Here, k is the number of latent factors; adjust based on your dataset.\n",
    "k = 50\n",
    "U, sigma, Vt = svds(R_train_demeaned, k=k)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the approximated ratings matrix using the SVD formula:\n",
    "# R_predicted = U Σ Vᵀ + user_mean\n",
    "R_train_predicted = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Use SVD Predictions to Compute Item-Item Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item similarity matrix shape (SVD predictions): (3706, 3706)\n"
     ]
    }
   ],
   "source": [
    "# Instead of computing cosine similarity on the original R_df,\n",
    "# we compute it on the SVD-reconstructed ratings matrix.\n",
    "R_predicted_df = pd.DataFrame(R_train_predicted, index=R_df.index, columns=R_df.columns)\n",
    "item_sim_matrix_svd = cosine_similarity(R_predicted_df.T)\n",
    "item_sim_df_svd = pd.DataFrame(item_sim_matrix_svd, index=R_df.columns, columns=R_df.columns)\n",
    "print(\"Item similarity matrix shape (SVD predictions):\", item_sim_df_svd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Apply PCA to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn's PCA to reduce dimensionality and then reconstruct the ratings.\n",
    "pca = PCA(n_components=k)\n",
    "# Fit PCA on the centered training matrix.\n",
    "R_train_pca = pca.fit_transform(R_train_demeaned)\n",
    "# Reconstruct: R_pca_pred = inverse_transform + user mean.\n",
    "R_pca_pred = pca.inverse_transform(R_train_pca) + user_ratings_mean.reshape(-1, 1)\n",
    "# Convert PCA predictions to a DataFrame.\n",
    "R_pca_pred_df = pd.DataFrame(R_pca_pred, index=R_df.index, columns=R_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item similarity matrix shape (PCA predictions): (3706, 3706)\n"
     ]
    }
   ],
   "source": [
    "# PCA-based similarity: Compute cosine similarity on R_pca_pred_df.T.\n",
    "item_sim_matrix_pca = cosine_similarity(R_pca_pred_df.T)\n",
    "item_sim_df_pca = pd.DataFrame(item_sim_matrix_pca, index=R_df.columns, columns=R_df.columns)\n",
    "print(\"Item similarity matrix shape (PCA predictions):\", item_sim_df_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Item-Based Collaborative Filtering Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend movies similar to a given movie using item-based collaborative filtering.\n",
    "  Parameters:\n",
    "  - movie_id (int): The ID of the reference movie.\n",
    "  - item_sim_df (DataFrame): Movie-to-movie cosine similarity matrix.\n",
    "  - movies_df (DataFrame): Movie metadata with descriptions.\n",
    "  - top_n (int): Number of similar movies to return.\n",
    "      \n",
    "  Returns:\n",
    "  - DataFrame: Recommended movies with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_movies(movie_id, item_sim_df, movies_df, top_n=5):\n",
    "    if movie_id not in item_sim_df.index:\n",
    "        print(f\"Movie ID {movie_id} not found in similarity matrix.\")\n",
    "        return None\n",
    "    # Retrieve similarity scores for the movie.\n",
    "    sim_scores = item_sim_df.loc[movie_id]\n",
    "    # Remove the movie itself.\n",
    "    sim_scores = sim_scores.drop(movie_id)\n",
    "    # Select the top_n most similar movies.\n",
    "    top_movie_ids = sim_scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    # Retrieve movie details.\n",
    "    recommendations = movies_df[movies_df['movieId'].isin(top_movie_ids)].copy()\n",
    "    recommendations['Similarity'] = recommendations['movieId'].apply(lambda x: sim_scores[x])\n",
    "    recommendations = recommendations.sort_values('Similarity', ascending=False)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movies similar to movie 318 (using SVD predictions):\n",
      "      movieId                     title  year          genres  \\\n",
      "1656     1704         Good Will Hunting  1997           Drama   \n",
      "35         36          Dead Man Walking  1995           Drama   \n",
      "589       593  The Silence of the Lambs  1991  Drama|Thriller   \n",
      "2432     2501               October Sky  1999           Drama   \n",
      "1337     1358               Sling Blade  1996  Drama|Thriller   \n",
      "\n",
      "                                            description  Similarity  \n",
      "1656  Will Hunting has a genius-level IQ but chooses...    0.777827  \n",
      "35    A justice drama based on a true story about a ...    0.725351  \n",
      "589   FBI trainee, Clarice Starling ventures into a ...    0.724682  \n",
      "2432  Based on the true story of Homer Hickam, a coa...    0.724449  \n",
      "1337  Karl Childers is a mentally disabled man who h...    0.708641  \n",
      "\n",
      "Top 5 movies similar to movie 318 (using PCA predictions):\n",
      "      movieId                     title  year          genres  \\\n",
      "1656     1704         Good Will Hunting  1997           Drama   \n",
      "589       593  The Silence of the Lambs  1991  Drama|Thriller   \n",
      "293       296              Pulp Fiction  1994     Crime|Drama   \n",
      "1337     1358               Sling Blade  1996  Drama|Thriller   \n",
      "523       527          Schindler's List  1993       Drama|War   \n",
      "\n",
      "                                            description  Similarity  \n",
      "1656  Will Hunting has a genius-level IQ but chooses...    0.801279  \n",
      "589   FBI trainee, Clarice Starling ventures into a ...    0.781623  \n",
      "293   A burger-loving hit man, his philosophical par...    0.736720  \n",
      "1337  Karl Childers is a mentally disabled man who h...    0.734808  \n",
      "523   The true story of how businessman Oskar Schind...    0.732285  \n"
     ]
    }
   ],
   "source": [
    "# Example: Recommend top 5 movies similar to a reference movie using SVD predictions.\n",
    "reference_movie = 318\n",
    "# Get recommendations using SVD-based similarity.\n",
    "similar_movies_svd = recommend_similar_movies(reference_movie, item_sim_df_svd, movies_df, top_n=5)\n",
    "print(f\"Top 5 movies similar to movie {reference_movie} (using SVD predictions):\")\n",
    "if similar_movies_svd is not None:\n",
    "    print(similar_movies_svd[['movieId', 'title', 'year', 'genres', 'description', 'Similarity']])\n",
    "else:\n",
    "    print(\"No recommendations available (SVD).\")\n",
    "\n",
    "# Get recommendations using PCA-based similarity.\n",
    "similar_movies_pca = recommend_similar_movies(reference_movie, item_sim_df_pca, movies_df, top_n=5)\n",
    "print(f\"\\nTop 5 movies similar to movie {reference_movie} (using PCA predictions):\")\n",
    "if similar_movies_pca is not None:\n",
    "    print(similar_movies_pca[['movieId', 'title', 'year', 'genres', 'description', 'Similarity']])\n",
    "else:\n",
    "    print(\"No recommendations available (PCA).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate the SVD Model Based on Recommended Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 (SVD): 0.0000\n",
      "Precision@5 (PCA): 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Ground truth: define a set of movie titles that are considered similar (this is domain-specific).\n",
    "# Adjust the set below based on your ground truth for movie 318.\n",
    "ground_truth_titles = {\n",
    "    \"The Green Mile\", \n",
    "    \"Forrest Gump\", \n",
    "    \"Pulp Fiction\", \n",
    "    \"The Godfather\", \n",
    "    \"Fight Club\"\n",
    "}\n",
    "\n",
    "# Calculate Precision@K Based on Movie Titles\n",
    "\n",
    "def precision_at_k(recommended_df, ground_truth_titles, k=5):\n",
    "    \"\"\"\n",
    "    Compute precision@k based on the recommended movie titles.\n",
    "    \n",
    "    Parameters:\n",
    "      recommended_df (DataFrame): DataFrame of recommended movies.\n",
    "      ground_truth_titles (set): Set of ground-truth similar movie titles.\n",
    "      k (int): Number of recommendations considered.\n",
    "      \n",
    "    Returns:\n",
    "      float: Precision@k value.\n",
    "    \"\"\"\n",
    "    # Get the recommended titles (limit to k recommendations).\n",
    "    recommended_titles = recommended_df.head(k)['title'].tolist()\n",
    "    hits = sum([1 for title in recommended_titles if title in ground_truth_titles])\n",
    "    return hits / k\n",
    "\n",
    "if similar_movies_svd is not None:\n",
    "    prec_svd = precision_at_k(similar_movies_svd, ground_truth_titles, k=5)\n",
    "    print(f\"Precision@5 (SVD): {prec_svd:.4f}\")\n",
    "    \n",
    "if similar_movies_pca is not None:\n",
    "    prec_pca = precision_at_k(similar_movies_pca, ground_truth_titles, k=5)\n",
    "    print(f\"Precision@5 (PCA): {prec_pca:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
