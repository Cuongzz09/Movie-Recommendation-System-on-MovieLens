{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Datasets Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies dataset shape: (3883, 5)\n",
      "   movieId                        title                        genres  year  \\\n",
      "0        1                    Toy Story   Animation|Children's|Comedy  1995   \n",
      "1        2                      Jumanji  Adventure|Children's|Fantasy  1995   \n",
      "2        3             Grumpier Old Men                Comedy|Romance  1995   \n",
      "3        4            Waiting to Exhale                  Comedy|Drama  1995   \n",
      "4        5  Father of the Bride Part II                        Comedy  1995   \n",
      "\n",
      "                                         description  \n",
      "0  Led by Woody, Andy's toys live happily in his ...  \n",
      "1  When siblings Judy and Peter discover an encha...  \n",
      "2  A family wedding reignites the ancient feud be...  \n",
      "3  Cheated on, mistreated and stepped on, the wom...  \n",
      "4  Just when George Banks has recovered from his ...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Load movie metadata with descriptions.\n",
    "# This file must include columns: movieId, title, genres, year, description.\n",
    "movies_df = pd.read_csv('movielens_movies_with_descriptions.csv')\n",
    "print(\"Movies dataset shape:\", movies_df.shape)\n",
    "print(movies_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings dataset shape: (1000209, 4)\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Load ratings data.\n",
    "# The ratings file is delimited by \"::\". Adjust file path as needed.\n",
    "ratings_df = pd.read_csv('movielens-1m/ratings.dat', sep='::', engine='python',\n",
    "                         header=None, names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "print(\"Ratings dataset shape:\", ratings_df.shape)\n",
    "print(ratings_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users dataset shape: (6040, 5)\n",
      "   userId Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Load user demographics for further analysis.\n",
    "users_df = pd.read_csv('movielens-1m/users.dat', sep='::', engine='python',\n",
    "                       header=None, names=['userId', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
    "print(\"Users dataset shape:\", users_df.shape)\n",
    "print(users_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First merge ratings and users on 'userId'\n",
    "# ratings_users = pd.merge(ratings_df, users_df, on='userId', how='left')\n",
    "# print(\"Merged ratings and users shape:\", ratings_users.shape)\n",
    "# print(ratings_users.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Then merge the result with movies on 'movieId'\n",
    "# full_df = pd.merge(ratings_users, movies_df, on='movieId', how='left')\n",
    "# print(\"Fully merged dataset shape:\", full_df.shape)\n",
    "# print(full_df.head(), \"\\n\")\n",
    "\n",
    "# # Now, full_df contains userId, movieId, rating, timestamp, Gender, Age, Occupation, Zip-code,\n",
    "# # as well as movie metadata: title, genres, year, description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check whether the number of unique movies in movies_with_des is the same as in movies or not.\n",
    "# full_df['test_title'] = full_df['title'] + ' (' + full_df['year'].astype(str) + ')'\n",
    "# full_df[['test_title', 'title', 'year']].head()\n",
    "# full_df['test_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create the User-Item Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Item matrix shape (R_df): (6040, 3706)\n"
     ]
    }
   ],
   "source": [
    "# Pivot the ratings data so that rows represent users and columns represent movies.\n",
    "# Missing ratings are filled with zeros.\n",
    "R_df = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "print(\"User-Item matrix shape (R_df):\", R_df.shape)\n",
    "# print(R_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Prepare Training Data and Apply SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (800167, 4)\n",
      "Test set size: (200042, 4)\n"
     ]
    }
   ],
   "source": [
    "# To follow the SVD formula from the PDF:\n",
    "#   1. Center the data: R_adj = R - mean(R) per user.\n",
    "#   2. Decompose the centered matrix: R_adj = U Σ Vᵀ.\n",
    "#   3. Reconstruct the prediction: R_predicted = U Σ Vᵀ + mean(R).\n",
    "\n",
    "# Split the ratings into training and test sets (80% train, 20% test).\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "print(\"Train set size:\", train_data.shape)\n",
    "print(\"Test set size:\", test_data.shape)\n",
    "\n",
    "# Build the training matrix from R_df and then mask the test ratings.\n",
    "R_train_df = R_df.copy()\n",
    "for idx, row in train_data.iterrows():\n",
    "    # We use the training data to build R_train_df (if you want to include only train ratings,\n",
    "    # you can set other entries to 0 – here we assume R_df already has all ratings and then we overwrite\n",
    "    # the ones in the test set to 0)\n",
    "    pass  # Alternatively, you can rebuild the training matrix directly from train_data.\n",
    "# For simplicity, here we assume R_df is built from all ratings and then we mask test entries.\n",
    "for idx, row in test_data.iterrows():\n",
    "    # Set the entry corresponding to each test rating to 0 (masking)\n",
    "    R_train_df.at[row['userId'], row['movieId']] = 0\n",
    "\n",
    "# Convert the training DataFrame to a NumPy array.\n",
    "R_train = R_train_df.values\n",
    "\n",
    "# Apply SVD Using the Formulas (Centering, Decomposition, Reconstruction)\n",
    "# Compute each user's mean rating from the training data.\n",
    "user_ratings_mean = np.mean(R_train, axis=1)\n",
    "# Center the training matrix (this is X_adj in the formulas).\n",
    "R_train_demeaned = R_train - user_ratings_mean.reshape(-1, 1)\n",
    "\n",
    "# Perform SVD on the demeaned training matrix.\n",
    "# Here, k is the number of latent factors; adjust based on your dataset.\n",
    "k = 50\n",
    "U, sigma, Vt = svds(R_train_demeaned, k=k)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the approximated ratings matrix using the SVD formula:\n",
    "# R_predicted = U Σ Vᵀ + user_mean\n",
    "R_train_predicted = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Use SVD Predictions to Compute Item-Item Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instead of computing cosine similarity on the original R_df,\n",
    "# # we compute it on the SVD-reconstructed ratings matrix.\n",
    "# R_predicted_df = pd.DataFrame(R_train_predicted, index=R_df.index, columns=R_df.columns)\n",
    "# item_sim_matrix = cosine_similarity(R_predicted_df.T)\n",
    "# item_sim_df = pd.DataFrame(item_sim_matrix, index=R_df.columns, columns=R_df.columns)\n",
    "# print(\"Item similarity matrix shape (from SVD predictions):\", item_sim_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item similarity matrix shape: (3706, 3706)\n"
     ]
    }
   ],
   "source": [
    "# Transpose R_df so that each row is a movie's ratings vector.\n",
    "item_sim_matrix = cosine_similarity(R_df.T)\n",
    "item_sim_df = pd.DataFrame(item_sim_matrix, index=R_df.columns, columns=R_df.columns)\n",
    "print(\"Item similarity matrix shape:\", item_sim_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Item-Based Collaborative Filtering Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend movies similar to a given movie using item-based collaborative filtering.\n",
    "  Parameters:\n",
    "  - movie_id (int): The ID of the reference movie.\n",
    "  - item_sim_df (DataFrame): Movie-to-movie cosine similarity matrix.\n",
    "  - movies_df (DataFrame): Movie metadata with descriptions.\n",
    "  - top_n (int): Number of similar movies to return.\n",
    "      \n",
    "  Returns:\n",
    "  - DataFrame: Recommended movies with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_similar_movies(movie_id, item_sim_df, movies_df, top_n=5):\n",
    "    if movie_id not in item_sim_df.index:\n",
    "        print(f\"Movie ID {movie_id} not found in similarity matrix.\")\n",
    "        return None\n",
    "    # Retrieve similarity scores for the movie.\n",
    "    sim_scores = item_sim_df.loc[movie_id]\n",
    "    # Remove the movie itself.\n",
    "    sim_scores = sim_scores.drop(movie_id)\n",
    "    # Select the top_n most similar movies.\n",
    "    top_movie_ids = sim_scores.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    # Retrieve movie details.\n",
    "    recommendations = movies_df[movies_df['movieId'].isin(top_movie_ids)].copy()\n",
    "    recommendations['Similarity'] = recommendations['movieId'].apply(lambda x: sim_scores[x])\n",
    "    recommendations = recommendations.sort_values('Similarity', ascending=False)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movies similar to movie 318 (using SVD predictions):\n",
      "      movieId                     title  year                genres  \\\n",
      "589       593  The Silence of the Lambs  1991        Drama|Thriller   \n",
      "293       296              Pulp Fiction  1994           Crime|Drama   \n",
      "604       608                     Fargo  1996  Crime|Drama|Thriller   \n",
      "523       527          Schindler's List  1993             Drama|War   \n",
      "1656     1704         Good Will Hunting  1997                 Drama   \n",
      "\n",
      "                                            description  Similarity  \n",
      "589   FBI trainee, Clarice Starling ventures into a ...    0.680923  \n",
      "293   A burger-loving hit man, his philosophical par...    0.658751  \n",
      "604   Jerry, a small-town Minnesota car salesman is ...    0.656308  \n",
      "523   The true story of how businessman Oskar Schind...    0.655410  \n",
      "1656  Will Hunting has a genius-level IQ but chooses...    0.631769  \n"
     ]
    }
   ],
   "source": [
    "# Example: Recommend top 5 movies similar to a reference movie (e.g., movie ID 318).\n",
    "reference_movie = 318\n",
    "similar_movies = recommend_similar_movies(reference_movie, item_sim_df, movies_df, top_n=5)\n",
    "print(f\"Top 5 movies similar to movie {reference_movie} (using SVD predictions):\")\n",
    "if similar_movies is not None:\n",
    "    print(similar_movies[['movieId', 'title', 'year', 'genres', 'description', 'Similarity']])\n",
    "else:\n",
    "    print(\"No recommendations available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate the SVD Model Based on Recommended Movie Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 for item-based recommendations (based on movie titles): 0.2000\n"
     ]
    }
   ],
   "source": [
    "# Ground truth: define a set of movie titles that are considered similar (this is domain-specific).\n",
    "# Adjust the set below based on your ground truth for movie 318.\n",
    "ground_truth_titles = {\n",
    "    \"The Green Mile\", \n",
    "    \"Forrest Gump\", \n",
    "    \"Pulp Fiction\", \n",
    "    \"The Godfather\", \n",
    "    \"Fight Club\"\n",
    "}\n",
    "\n",
    "# Calculate Precision@K Based on Movie Titles\n",
    "\n",
    "def precision_at_k(recommended_df, ground_truth_titles, k=5):\n",
    "    \"\"\"\n",
    "    Compute precision@k based on the recommended movie titles.\n",
    "    \n",
    "    Parameters:\n",
    "      recommended_df (DataFrame): DataFrame of recommended movies.\n",
    "      ground_truth_titles (set): Set of ground-truth similar movie titles.\n",
    "      k (int): Number of recommendations considered.\n",
    "      \n",
    "    Returns:\n",
    "      float: Precision@k value.\n",
    "    \"\"\"\n",
    "    # Get the recommended titles (limit to k recommendations).\n",
    "    recommended_titles = recommended_df.head(k)['title'].tolist()\n",
    "    hits = sum([1 for title in recommended_titles if title in ground_truth_titles])\n",
    "    return hits / k\n",
    "\n",
    "if similar_movies is not None:\n",
    "    prec = precision_at_k(similar_movies, ground_truth_titles, k=5)\n",
    "    print(f\"Precision@5 for item-based recommendations (based on movie titles): {prec:.4f}\")\n",
    "else:\n",
    "    print(\"Cannot compute precision without recommendations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
